pip install node2vec


!pip install ipywidgets


pip install gradio


import pandas as pd
import networkx as nx
import numpy as np
from node2vec import Node2Vec
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
from urllib.parse import urlparse
import seaborn as sns
from sklearn.neural_network import MLPClassifier
from keras.models import Sequential
from sklearn.ensemble import RandomForestClassifier
from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense
import ipywidgets as widgets
from IPython.display import display
import gradio as gr
from gensim.models import Word2Vec
import tensorflow as tf
from sklearn.manifold import TSNE
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.model_selection import GridSearchCV
from imblearn.over_sampling import SMOTE
from sklearn.metrics import roc_auc_score


# Load the dataset
df = pd.read_csv("/content/drive/MyDrive/Dataset_17972.csv", encoding= 'utf-8')  # Replace "your_dataset.csv" with the actual file path
df.head(20)




df = df.drop(['Title','Date'], axis=1)
df.head(5)


df['Category'].value_counts()
df['Class'].unique()

df['Class'] = df['Class'].astype('category').cat.codes
df['Class'].value_counts()

df.head()

df.isnull().sum()

dup = df[df.duplicated(['Statement'])]
print(dup.shape)
print(df.shape)


df = df.drop_duplicates(['Statement'])
print(df.shape)

sns.countplot(x='Class', data=df)

plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Count of Real vs Fake')
plt.show()

# Group the data by Category and calculate the count and percentage of fake and real news
category_counts = df.groupby('Category')['Class'].value_counts().unstack()
category_counts['Total'] = category_counts.sum(axis=1)
category_counts['Fake %'] = (category_counts[0] / category_counts['Total']) * 100
category_counts['Real %'] = (category_counts[1] / category_counts['Total']) * 100

# Display the result
print(category_counts)


source_counts = df.groupby('Source')['Class'].value_counts().unstack()
source_counts['Total'] = source_counts.sum(axis=1)
source_counts['Fake %'] = (source_counts[0] / source_counts['Total']) * 100
source_counts['Real %'] = (source_counts[1] / source_counts['Total']) * 100

# Display the result
print(source_counts)

# Extract domain feature from the URL and assign it to the "Source" column
#df['Source'] = df['Source'].apply(lambda url: urlparse(url).netloc)



# Example output
print(df['Source'].head())

# Filter the DataFrame to include only real news
real_news = df[df["Class"] == 1]

# Count the occurrences of each unique source URL for real news
url_counts = real_news["Source"].value_counts()

# Reset the index and create a new DataFrame
url_counts_df = url_counts.reset_index()
url_counts_df.columns = ["Source", "Count"]

# Plot the histogram
plt.figure(figsize=(12, 6))
plt.hist(url_counts_df["Source"], bins=993, rwidth=0.9)
url_counts.plot(kind="bar")
plt.xlabel("Source URLs")
plt.ylabel("Number of Real News")
plt.title("Histogram of Real News per Source URL")
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

# Filter the DataFrame to include only real news
fake_news = df[df["Class"] == 0]

# Count the occurrences of each unique source URL for real news
url_counts = fake_news["Source"].value_counts()

# Reset the index and create a new DataFrame
url_counts_df = url_counts.reset_index()
url_counts_df.columns = ["Source", "Count"]

# Plot the histogram
plt.figure(figsize=(12, 6))
plt.hist(url_counts_df["Source"], bins=993, rwidth=0.9)
url_counts.plot(kind="bar")
plt.xlabel("Source URLs")
plt.ylabel("Number of Fake News")
plt.title("Histogram of Fake News per Source URL")
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

# Create the web graph
web_graph = nx.Graph()
for source in df["Source"]:
    web_graph.add_node(source)

 # Create a figure and axis
fig, ax = plt.subplots(figsize=(10, 10), facecolor='black')

# Plot the web graph
pos = nx.spring_layout(web_graph)  # Define the layout algorithm
nx.draw(web_graph, pos, with_labels=True, node_size=50, node_color='blue', edge_color='red', alpha=0.7, ax=ax)

# Show the plot
plt.show()



# Generate node embeddings
node2vec = Node2Vec(web_graph, dimensions=128, walk_length=30, num_walks=200)
nmodel = node2vec.fit(window=10, min_count=1)
# Save the node2vec model using its built-in save method
#node2vec_model_path = "/F:/thesis/Saved Models/node2vec_model.model"
#model.save(node2vec_model_path)


# Extract features from the URLs
features = []
for source in df["Source"]:
    features.append(nmodel.wv[source])
    # Convert the features to a NumPy array
features_array = np.array(features)

# Use t-SNE for visualization
tsne = TSNE(n_components=2, random_state=42)
embedding_2d = tsne.fit_transform(features_array)

# Reset the index of the DataFrame
df = df.reset_index(drop=True)

# Create a figure and axis for t-SNE visualization
fig, ax = plt.subplots(figsize=(7, 7))

# Plot the node embeddings with reduced transparency (alpha)
ax.scatter(embedding_2d[:, 0], embedding_2d[:, 1], c='blue', alpha=0.5)

# Annotate a random subset of points with the URLs
num_points_to_annotate = min(len(df["Source"]), 20)  # You can change the number of points to annotate
annotated_points = np.random.choice(len(df["Source"]), num_points_to_annotate, replace=False)

for i in annotated_points:
    ax.annotate(df["Source"][i], (embedding_2d[i, 0], embedding_2d[i, 1]), color='black')

# Show the t-SNE plot
plt.show()



for i in range(5):  # Change the number as per your requirement
    print(f"URL: {df['Source'][i]}")
    print(f"Features: {features[i]}")
    print()
#df.head(5)

# Prepare the data for classification
X = pd.DataFrame(features)
y = df["Class"]  # Assuming the Class field contains the labels (real or fake)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
x_val_train, x_val_test, y_val_train, y_val_test = train_test_split(X_train, y_train , random_state=4,test_size=0.12)

print(X_train.shape)  # 80% Train set
print(X_test.shape)

C_list = [0.1, 1, 10, 100]
gamma_list = [0.001, 0.01, 0.1, 1]



best_acc = -np.inf

for C in C_list:
  for gamma in gamma_list:
    svm_test = SVC(C=C, gamma=gamma)
    svm_test.fit(x_val_train, y_val_train)
    predictions = svm_test.predict(x_val_test)
    acc = accuracy_score(y_val_test, predictions)
    if acc > best_acc:
      best_acc = acc
      best_C = C
      best_gamma = gamma

print(best_acc)
print(best_C)
print(best_gamma)

# Train and evaluate the SVM classifier
svm = SVC(C=best_C, kernel='linear', gamma=best_gamma)
svm.fit(X_train, y_train)

#import joblib
#svm = SVC()
#svm.fit(X_train, y_train)
svm_predictions = svm.predict(X_test)
t_pred = svm.predict(X_train)
svm_train_accuracy = accuracy_score(y_train, t_pred)
svm_accuracy = accuracy_score(y_test, svm_predictions)
print("SVM Test Accuracy:", svm_accuracy)
print("SVM Train Accuracy:", svm_train_accuracy)

ms_pre = precision_score(y_test, svm_predictions)
print("Precision :", ms_pre)

ms_rec = recall_score(y_test, svm_predictions)
print("Recall :", ms_rec)

ms_f3 = f1_score(y_test, svm_predictions)
print("F1 :", ms_f3)

# Save SVM model
#svm_model_path = "/F:/thesis/Saved Models/svm_model.pkl"
#joblib.dump(svm, svm_model_path)

# Train and evaluate the Logistic Regression classifier
logistic_regression = LogisticRegression()
logistic_regression.fit(X_train, y_train)
lr_train_pred = logistic_regression.predict(X_train)
lr_predictions = logistic_regression.predict(X_test)
lr_train_accuracy = accuracy_score(y_train, lr_train_pred)
lr_accuracy = accuracy_score(y_test, lr_predictions)
print("Logistic Regression Test Accuracy:", lr_accuracy)
print("Logistic Regression Train Accuracy:", lr_train_accuracy)

lr_pre = precision_score(y_test, lr_predictions)
print("Precision :", lr_pre)

lr_rec = recall_score(y_test, lr_predictions)
print("Recall :", lr_rec)

lr_f3 = f1_score(y_test, lr_predictions)
print("F1 :", lr_f3)



# Hyperparameter Tuning
param_grid = {'C': [0.1, 1, 10]}
grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)
grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_

# Evaluate the model
train_predictions = best_model.predict(X_train)
test_predictions = best_model.predict(X_test)

train_accuracy = accuracy_score(y_train, train_predictions)
test_accuracy = accuracy_score(y_test, test_predictions)
precision = precision_score(y_test, test_predictions)
recall = recall_score(y_test, test_predictions)
f1 = f1_score(y_test, test_predictions)



print("Logistic Regression Train Accuracy:", train_accuracy)
print("Logistic Regression Test Accuracy:", test_accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)


# Save Logistic Regression model
#logreg_model_path = "/F:/thesis/Saved Models/logreg_model.pkl"
#joblib.dump(best_model, logreg_model_path)


# Train and evaluate ANN classifier
ann = MLPClassifier(hidden_layer_sizes=(128, 64), activation="relu", random_state=42)
ann.fit(X_train, y_train)
ann_predictions = ann.predict(X_test)
ann_train_pred = ann.predict(X_train)
ann_accuracy = accuracy_score(y_test, ann_predictions)
ann_train_accuracy = accuracy_score(y_train, ann_train_pred)
ann_precision = precision_score(y_test, ann_predictions)
ann_recall = recall_score(y_test, ann_predictions)
ann_f1 = f1_score(y_test, ann_predictions)

print("ANN Results:")
print("Accuracy:", ann_accuracy)
print("Train Accuracy:", ann_train_accuracy)
print("Precision:", ann_precision)
print("Recall:", ann_recall)
print("F1-score:", ann_f1)

# Define the CNN model architecture
model = Sequential()
model.add(Embedding(input_dim=X.shape[0], output_dim=X.shape[1], input_length=X.shape[1]))
model.add(Conv1D(filters=256, kernel_size=5, activation='relu'))
model.add(GlobalMaxPooling1D())
model.add(Dense(units=64, activation='relu'))
model.add(Dense(units=1, activation='sigmoid'))

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

 #Evaluate the CNN model
cnn_probabilities = model.predict(X_test).flatten()
cnn_predictions = np.where(cnn_probabilities >= 0.3, 1, 0)
cnn_accuracy = accuracy_score(y_test, cnn_predictions)
cnn_train_probabilities = model.predict(X_train).flatten()
cnn_train_predictions = np.where(cnn_train_probabilities >= 0.3, 1, 0)
cnn_train_accuracy = accuracy_score(y_train, cnn_train_predictions)
cnn_precision = precision_score(y_test, cnn_predictions)
cnn_recall = recall_score(y_test, cnn_predictions)
cnn_f1 = f1_score(y_test, cnn_predictions)

print("CNN Results:")
print("Accuracy:", cnn_accuracy)
print("Train Accuracy:", cnn_train_accuracy)
print("Precision:", cnn_precision)
print("Recall:", cnn_recall)
print("F1-score:", cnn_f1)

# Save CNN model
#cnn_model_path = "/F:/thesis/Saved Models/cnn_model.pkl"
#joblib.dump(model, cnn_model_path)


# Create a Random Forest Classifier
rf_classifier = RandomForestClassifier()

# Train the classifier
rf_classifier.fit(X_train, y_train)

# Make predictions on the test set
predictions = rf_classifier.predict(X_test)
train_predictions = rf_classifier.predict(X_train)

# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)
train_accuracy = accuracy_score(y_train, train_predictions)
print("Train Accuracy:", train_accuracy)

# Calculate precision, recall, and F1 score
precision = precision_score(y_test, predictions)
recall = recall_score(y_test, predictions)
f1 = f1_score(y_test, predictions)

# Print the metrics
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)


def predict_fake_news(source_url):
    try:
        # Extract features for the input source URL using node2vec model
        input_feature = nmodel.wv[source_url]

        # Perform predictions using your models
        # Replace with your prediction code for SVM, CNN, and Logistic Regression
        svm_prediction = svm.predict([input_feature])[0]  # Ensure you provide a list of features

        cnn_probabilities = model.predict(np.array([input_feature])).flatten()
        cnn_prediction = int(np.where(cnn_probabilities >= 0.3, 1, 0))

        lr_prediction = best_model.predict([input_feature])[0]  # Ensure you provide a list of features

        combined_prediction = int((svm_prediction + lr_prediction + cnn_prediction) >= 2)

        return "Real" if combined_prediction == 1 else "Fake"

    except Exception as e:
        print("An error occurred:", e)
        return "Error"

while True:
    source_url = input("Enter Source URL (or 'exit' to stop): ")
    if source_url.lower() == "exit":
        break
    prediction = predict_fake_news(source_url)
    print("Combined Prediction:", prediction)

